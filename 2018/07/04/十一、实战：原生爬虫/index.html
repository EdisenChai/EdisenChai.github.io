<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    
    <title>十一、实战：原生爬虫 | Edisenの博客</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content="Python系统课程-C1" />
    
    <meta name="description" content="11 原生爬虫11.1 爬虫前奏爬虫前奏a.明确目的b.找到数据对应的网页c.分析网页的结构找到数据所在的标签位置d.模拟http请求,向服务器发送这个请求,获取到服务器返回给我们的html(返回的是完整的html数据);    用正则表达式提取我们需要的数据 11.2 爬虫及断点调试a.断点打好，F5运行–F10单步–F5跳断点(从一个断点跳到下一个断点)–F11进入某个对象或函数的内部;b.">
<meta name="keywords" content="Python系统课程-C1">
<meta property="og:type" content="article">
<meta property="og:title" content="十一、实战：原生爬虫">
<meta property="og:url" content="http://yoursite.com/2018/07/04/十一、实战：原生爬虫/index.html">
<meta property="og:site_name" content="Edisenの博客">
<meta property="og:description" content="11 原生爬虫11.1 爬虫前奏爬虫前奏a.明确目的b.找到数据对应的网页c.分析网页的结构找到数据所在的标签位置d.模拟http请求,向服务器发送这个请求,获取到服务器返回给我们的html(返回的是完整的html数据);    用正则表达式提取我们需要的数据 11.2 爬虫及断点调试a.断点打好，F5运行–F10单步–F5跳断点(从一个断点跳到下一个断点)–F11进入某个对象或函数的内部;b.">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2018/07/04/十一、实战：原生爬虫/spider.png">
<meta property="og:updated_time" content="2018-07-07T09:37:49.402Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="十一、实战：原生爬虫">
<meta name="twitter:description" content="11 原生爬虫11.1 爬虫前奏爬虫前奏a.明确目的b.找到数据对应的网页c.分析网页的结构找到数据所在的标签位置d.模拟http请求,向服务器发送这个请求,获取到服务器返回给我们的html(返回的是完整的html数据);    用正则表达式提取我们需要的数据 11.2 爬虫及断点调试a.断点打好，F5运行–F10单步–F5跳断点(从一个断点跳到下一个断点)–F11进入某个对象或函数的内部;b.">
<meta name="twitter:image" content="http://yoursite.com/2018/07/04/十一、实战：原生爬虫/spider.png">
    

    
        <link rel="alternate" href="/atom.xml" title="Edisenの博客" type="application/atom+xml" />
    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.0.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    


</head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">主页</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python爬虫/">Python爬虫</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/python">Python小道</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/linux">Linux实战</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/life">随便写点儿</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/money">☞赏点儿水果☜</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">关于</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/Python/">Python</a>
    </h1>
</div>
                        <div class="main-body-content">
                            <article id="post-十一、实战：原生爬虫" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        十一、实战：原生爬虫
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2018/07/04/十一、实战：原生爬虫/" class="article-date">
            <time datetime="2018-07-04T05:22:56.000Z" itemprop="datePublished">2018-07-04</time>
        </a>
    </div>

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/Python系统课程-C1/">Python系统课程-C1</a>
    </div>

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h3 id="11-原生爬虫"><a href="#11-原生爬虫" class="headerlink" title="11 原生爬虫"></a>11 原生爬虫</h3><h4 id="11-1-爬虫前奏"><a href="#11-1-爬虫前奏" class="headerlink" title="11.1 爬虫前奏"></a>11.1 爬虫前奏</h4><p>爬虫前奏<br>a.明确目的<br>b.找到数据对应的网页<br>c.分析网页的结构找到数据所在的标签位置<br>d.模拟http请求,向服务器发送这个请求,获取到服务器返回给我们的html(返回的是完整的html数据);<br>    用正则表达式提取我们需要的数据</p>
<h4 id="11-2-爬虫及断点调试"><a href="#11-2-爬虫及断点调试" class="headerlink" title="11.2 爬虫及断点调试"></a>11.2 爬虫及断点调试</h4><p>a.断点打好，F5运行–F10单步–F5跳断点(从一个断点跳到下一个断点)–F11进入某个对象或函数的内部;<br>b. 作用：鼠标悬停在变量上方后会出现变量的状态，可看到相应的属性和值。</p>
<p>#####爬虫一：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">from urllib import request</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">class Spider():</span><br><span class="line">    url = <span class="string">'https://www.panda.tv/cate/lol?pdt=1.24.s1.3.1loapcheq15'</span></span><br><span class="line">    <span class="comment"># 设置中间 匹配 所有 且非贪婪</span></span><br><span class="line">    root_pattern = <span class="string">'&lt;div class="video-info"&gt;[\s\S]*?&lt;/div&gt;'</span></span><br><span class="line">    <span class="comment"># __私有方法</span></span><br><span class="line">    def __fetch_content(self):</span><br><span class="line">        <span class="comment"># 爬取网页的初始数据</span></span><br><span class="line">        r = request.urlopen(Spider.url)</span><br><span class="line">        <span class="comment">#print(r)</span></span><br><span class="line">        htmls = r.read()</span><br><span class="line">        htmls = str(htmls, encoding=<span class="string">'utf-8'</span>) <span class="comment"># 得到的数据进行转码</span></span><br><span class="line">        a = 2</span><br><span class="line">        <span class="comment">#print(htmls)</span></span><br><span class="line">        <span class="built_in">return</span> htmls</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对初始数据进行处理</span></span><br><span class="line">    def __analysis(self,htmls):</span><br><span class="line">        <span class="comment">#得到所有names的数据列表：infos</span></span><br><span class="line">        infos = re.findall(Spider.root_pattern,htmls)</span><br><span class="line">        <span class="comment">#print(type(infos))</span></span><br><span class="line">        <span class="comment">#print(infos[1])</span></span><br><span class="line">        name_pattern = <span class="string">'&lt;/i&gt;[\w\W]*?&lt;/span&gt;'</span></span><br><span class="line">        number_pattern = <span class="string">'&lt;span class="video-number"&gt;(.*)&lt;/span&gt;'</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> names <span class="keyword">in</span> infos:</span><br><span class="line">            <span class="comment">#提取处理</span></span><br><span class="line">            number_groups = re.search(number_pattern,names)</span><br><span class="line">            number = number_groups.group(1)</span><br><span class="line"></span><br><span class="line">            name_pre = re.findall(name_pattern,names)</span><br><span class="line">            <span class="comment"># print(name_pre[0])</span></span><br><span class="line">            name_no_space = name_pre[0].replace(<span class="string">'\n'</span>,<span class="string">''</span>)</span><br><span class="line">            name_space = re.search(<span class="string">'&lt;/i&gt;(.*)&lt;/span&gt;'</span>,name_no_space)</span><br><span class="line">            name = name_space.group(1).replace(<span class="string">' '</span>,<span class="string">''</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">'主播：'</span>+name+<span class="string">",  人气： "</span>+number)</span><br><span class="line">        </span><br><span class="line">    def go(self):</span><br><span class="line">        htmls = self.__fetch_content()</span><br><span class="line">        self.__analysis(htmls)</span><br><span class="line"></span><br><span class="line">spider = Spider()</span><br><span class="line">spider.go()</span><br></pre></td></tr></table></figure></p>
<h5 id="爬虫二："><a href="#爬虫二：" class="headerlink" title="爬虫二："></a>爬虫二：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">from urllib import request</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">class Spider():</span><br><span class="line">    url = <span class="string">'https://www.panda.tv/cate/lol?pdt=1.24.s1.3.1loapcheq15'</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置中间 匹配 所有 且非贪婪 加() 去掉外层 不需要的数据</span></span><br><span class="line">    root_pattern = <span class="string">'&lt;div class="video-info"&gt;([\s\S]*?)&lt;/div&gt;'</span></span><br><span class="line">    name_pattern = <span class="string">'&lt;/i&gt;([\s\S]*?)&lt;/span&gt;'</span></span><br><span class="line">    number_pattern = <span class="string">'&lt;span class="video-number"&gt;([\w\W]*?)&lt;/span&gt;'</span></span><br><span class="line">    <span class="comment"># __私有方法</span></span><br><span class="line">    def __fetch_content(self):</span><br><span class="line">        <span class="comment"># 爬取网页的初始数据</span></span><br><span class="line">        r = request.urlopen(Spider.url)</span><br><span class="line">        <span class="comment">#print(r)</span></span><br><span class="line">        htmls = r.read()</span><br><span class="line">        htmls = str(htmls, encoding=<span class="string">'utf-8'</span>) <span class="comment"># 得到的数据进行转码</span></span><br><span class="line">        a = 2</span><br><span class="line">        <span class="comment">#print(htmls)</span></span><br><span class="line">        <span class="built_in">return</span> htmls</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对初始数据进行处理</span></span><br><span class="line">    def __analysis(self,htmls):</span><br><span class="line">        <span class="comment">#得到所有names的数据列表：infos</span></span><br><span class="line">        root_htmls = re.findall(Spider.root_pattern,htmls)</span><br><span class="line">        name_list = []</span><br><span class="line">        number_list = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> each_html <span class="keyword">in</span> root_htmls:</span><br><span class="line">            <span class="comment">#得到name的一个列表 </span></span><br><span class="line">            <span class="comment"># ['\n                                                                        七堇年华小七                      ', '\n</span></span><br><span class="line">            <span class="comment">#                  ']</span></span><br><span class="line">            name_ori = re.findall(Spider.name_pattern, each_html)</span><br><span class="line">            <span class="comment">#从list name里获取str名字</span></span><br><span class="line">            <span class="comment">#                                                            七堇年华小七</span></span><br><span class="line">            name_ori = name_ori[0]</span><br><span class="line">            <span class="comment"># 除去空格、换行，得到名字：七堇年华小七</span></span><br><span class="line">            name = name_ori.replace(<span class="string">' '</span>,<span class="string">''</span>)</span><br><span class="line">            number = re.findall(Spider.number_pattern, each_html)</span><br><span class="line">            <span class="comment">#从list number 得到str number</span></span><br><span class="line">            number = number[0]</span><br><span class="line">            <span class="comment">#按照顺序分别添加到name_list、number_list</span></span><br><span class="line">            name_list.append(name)</span><br><span class="line">            number_list.append(number)</span><br><span class="line">            <span class="comment"># print(type(name_space[0])) # str</span></span><br><span class="line">            <span class="comment"># print(type(name_space))  # list</span></span><br><span class="line">            <span class="comment"># print(name)</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 打印出来</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(0,len(name_list)):</span><br><span class="line">              <span class="built_in">print</span>(name_list[index]+<span class="string">': '</span>+number_list[index])</span><br><span class="line"></span><br><span class="line">                </span><br><span class="line">       </span><br><span class="line">        </span><br><span class="line">    def go(self):</span><br><span class="line">        htmls = self.__fetch_content()</span><br><span class="line">        self.__analysis(htmls)</span><br><span class="line"></span><br><span class="line">spider = Spider()</span><br><span class="line">spider.go()</span><br></pre></td></tr></table></figure>
<img src="/2018/07/04/十一、实战：原生爬虫/spider.png" title="爬虫">
<h5 id="爬虫三："><a href="#爬虫三：" class="headerlink" title="爬虫三："></a>爬虫三：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">from urllib import request</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">class Spider():</span><br><span class="line">    url = <span class="string">'https://www.panda.tv/cate/lol?pdt=1.24.s1.3.1loapcheq15'</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置中间 匹配 所有 且非贪婪 加() 去掉外层 不需要的数据</span></span><br><span class="line">    root_pattern = <span class="string">'&lt;div class="video-info"&gt;([\s\S]*?)&lt;/div&gt;'</span></span><br><span class="line">    name_pattern = <span class="string">'&lt;/i&gt;([\s\S]*?)&lt;/span&gt;'</span></span><br><span class="line">    number_pattern = <span class="string">'&lt;span class="video-number"&gt;([\w\W]*?)&lt;/span&gt;'</span></span><br><span class="line">    <span class="comment"># __私有方法</span></span><br><span class="line">    def __fetch_content(self):</span><br><span class="line">        <span class="comment"># 爬取网页的初始数据</span></span><br><span class="line">        r = request.urlopen(Spider.url)</span><br><span class="line">        <span class="comment">#print(r)</span></span><br><span class="line">        htmls = r.read()</span><br><span class="line">        htmls = str(htmls, encoding=<span class="string">'utf-8'</span>) <span class="comment"># 得到的数据进行转码</span></span><br><span class="line">        a = 2</span><br><span class="line">        <span class="comment">#print(htmls)</span></span><br><span class="line">        <span class="built_in">return</span> htmls</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对初始数据进行处理</span></span><br><span class="line">    def __analysis(self,htmls):</span><br><span class="line">        <span class="comment">#得到所有names的数据列表：infos</span></span><br><span class="line">        root_htmls = re.findall(Spider.root_pattern,htmls)</span><br><span class="line">        name_number_list = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> each_html <span class="keyword">in</span> root_htmls:</span><br><span class="line">            <span class="comment">#得到name的一个列表 </span></span><br><span class="line">            <span class="comment"># ['\n                                                                        七堇年华小七                      ', '\n</span></span><br><span class="line">            <span class="comment">#                  ']</span></span><br><span class="line">            name_ori = re.findall(Spider.name_pattern, each_html)</span><br><span class="line">            <span class="comment">#从list name里获取str名字</span></span><br><span class="line">            <span class="comment">#                                                            七堇年华小七</span></span><br><span class="line">            name_ori = name_ori[0]</span><br><span class="line">            <span class="comment"># 除去空格，得到名字：七堇年华小七</span></span><br><span class="line">            name = name_ori.replace(<span class="string">' '</span>,<span class="string">''</span>)</span><br><span class="line">            <span class="comment"># 除去名字前的 \n ：'\nSJY潇洒'</span></span><br><span class="line">            name = name.replace(<span class="string">'\n'</span>,<span class="string">''</span>)</span><br><span class="line">            number = re.findall(Spider.number_pattern, each_html)</span><br><span class="line">            <span class="comment">#从list number 得到str number</span></span><br><span class="line">            number = number[0]</span><br><span class="line">            <span class="comment"># 添加进一个dict里,要注意字典的格式 key:value</span></span><br><span class="line">            name_number_dict = &#123;<span class="string">'name'</span>:name, <span class="string">'number'</span>:number&#125;</span><br><span class="line">            <span class="comment">#添加进；list 里</span></span><br><span class="line">            name_number_list.append(name_number_dict)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">return</span> name_number_list</span><br><span class="line"></span><br><span class="line">    def __refine(self,name_number_list):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> name_number_list:</span><br><span class="line">            <span class="built_in">print</span>(x)</span><br><span class="line">            </span><br><span class="line">    def go(self):</span><br><span class="line">        htmls = self.__fetch_content()</span><br><span class="line">        name_number_list = self.__analysis(htmls)</span><br><span class="line">        self.__refine(name_number_list)</span><br><span class="line"></span><br><span class="line">spider = Spider()</span><br><span class="line">spider.go()</span><br></pre></td></tr></table></figure>
<h5 id="最终爬虫-格式比较规范-："><a href="#最终爬虫-格式比较规范-：" class="headerlink" title="最终爬虫(格式比较规范)："></a>最终爬虫(格式比较规范)：</h5><p>1.推荐平级的函数 ，清晰;<br>关于注释推荐:<br>a. ‘’’多行注释’’’   写在函数里面，使用缩进;<br>b. 单行注释 推荐 写在 代码上一行 ，易于阅读;<br>c. 善于利用空行 方便阅读;<br>d. 倡导函数行数控制在10-20行之间，是函数小巧，提高复用性及阅读性;<br>2.中大型爬虫：<br>a. BeautifulSoup库，有简单方法帮助快速提炼内容;<br>b. Scrapy爬虫框架;<br>注意：要根据实际需要去学习框架！<br>3.在大段代码里找到某个函数：ctrl+shift+O<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""</span><span class="string">" </span></span><br><span class="line"><span class="string">爬虫模块</span></span><br><span class="line"><span class="string"> "</span><span class="string">""</span></span><br><span class="line">from urllib import request</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">class Spider():</span><br><span class="line">    <span class="string">""</span><span class="string">" </span></span><br><span class="line"><span class="string">    爬虫类 </span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    url = <span class="string">'https://www.panda.tv/cate/lol?pdt=1.24.s1.3.1loapcheq15'</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置中间 匹配 所有 且非贪婪 加() 去掉外层 不需要的数据</span></span><br><span class="line">    root_pattern = <span class="string">'&lt;div class="video-info"&gt;([\s\S]*?)&lt;/div&gt;'</span></span><br><span class="line">    name_pattern = <span class="string">'&lt;/i&gt;([\s\S]*?)&lt;/span&gt;'</span></span><br><span class="line">    number_pattern = <span class="string">'&lt;span class="video-number"&gt;([\w\W]*?)&lt;/span&gt;'</span></span><br><span class="line">    </span><br><span class="line">    def __fetch_content(self):</span><br><span class="line">        <span class="string">""</span><span class="string">" 抓取基本内容  __私有方法"</span><span class="string">""</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 爬取网页的初始数据</span></span><br><span class="line">        r = request.urlopen(Spider.url)</span><br><span class="line">        htmls = r.read()</span><br><span class="line">        htmls = str(htmls, encoding=<span class="string">'utf-8'</span>) <span class="comment"># 得到的数据进行转码</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">return</span> htmls</span><br><span class="line"></span><br><span class="line">    def __analysis(self,htmls):</span><br><span class="line">        <span class="string">""</span><span class="string">" 对初始数据进行处理 "</span><span class="string">""</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#得到所有names的数据列表：infos</span></span><br><span class="line">        root_htmls = re.findall(Spider.root_pattern,htmls)</span><br><span class="line">        name_number_list = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> each_html <span class="keyword">in</span> root_htmls:</span><br><span class="line">            <span class="comment">#得到name的一个列表 </span></span><br><span class="line">            <span class="comment"># ['\n                                                                        七堇年华小七                      ', '\n</span></span><br><span class="line">            <span class="comment">#                  ']</span></span><br><span class="line">            name = re.findall(Spider.name_pattern, each_html)</span><br><span class="line">            number = re.findall(Spider.number_pattern, each_html)</span><br><span class="line">          </span><br><span class="line">            <span class="comment"># 添加进一个dict里,要注意字典的格式 key:value</span></span><br><span class="line">            name_number_dict = &#123;<span class="string">'name'</span>:name, <span class="string">'number'</span>:number&#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#添加进；list 里</span></span><br><span class="line">            name_number_list.append(name_number_dict)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">return</span> name_number_list</span><br><span class="line"></span><br><span class="line">    def __refine(self,name_number_list):</span><br><span class="line">        <span class="string">""</span><span class="string">" 进一步处理数据 "</span><span class="string">""</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将原始的name--number dict 的数据再处理一下：</span></span><br><span class="line">        <span class="comment"># &#123;'name': ['\n                                                                        LOL丶摇摆哥                      ', '\n</span></span><br><span class="line">        <span class="comment">#                               '], 'number': ['7.3万']&#125;</span></span><br><span class="line">        l = lambda each_name_number: &#123;<span class="string">'name'</span>:each_name_number[<span class="string">'name'</span>][0].strip(),</span><br><span class="line">                                      <span class="string">'number'</span>:each_name_number[<span class="string">'number'</span>][0]&#125;</span><br><span class="line">        <span class="built_in">return</span> map(l, name_number_list)</span><br><span class="line"></span><br><span class="line">    def __sort(self,name_numbers):</span><br><span class="line">        <span class="string">""</span><span class="string">" 排序 "</span><span class="string">""</span></span><br><span class="line">        name_numbers = sorted(name_numbers, key=self.__sort__seed, reverse = True)</span><br><span class="line">        <span class="built_in">return</span> name_numbers  </span><br><span class="line"></span><br><span class="line">    def __sort__seed(self, name_number):</span><br><span class="line">        <span class="string">""</span><span class="string">" 排序准备  "</span><span class="string">""</span></span><br><span class="line">        nu = re.findall(<span class="string">'\d*'</span>,name_number[<span class="string">'number'</span>])</span><br><span class="line">        number = <span class="built_in">float</span>(nu[0])</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'万'</span> <span class="keyword">in</span> name_number[<span class="string">'number'</span>]:</span><br><span class="line">            number = number * 10000</span><br><span class="line"></span><br><span class="line">        <span class="built_in">return</span> number </span><br><span class="line"></span><br><span class="line">    def __show(self,name_numbers):</span><br><span class="line">        <span class="string">""</span><span class="string">" 展示数据 "</span><span class="string">""</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#count = 1</span></span><br><span class="line">        <span class="keyword">for</span> rank <span class="keyword">in</span> range(0,len(name_numbers)):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">'Rank: '</span>+str(rank+1)+<span class="string">'--'</span>+</span><br><span class="line">                   name_numbers[rank][<span class="string">'name'</span>]+<span class="string">'----'</span>+</span><br><span class="line">                   name_numbers[rank][<span class="string">'number'</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># for name_number in name_numbers:</span></span><br><span class="line">        <span class="comment">#     print('Rank '+str(count) + '--'+ name_number['name']+'----'+name_number['number'])</span></span><br><span class="line">        <span class="comment">#     count += 1</span></span><br><span class="line">        </span><br><span class="line">    def go(self):</span><br><span class="line">        <span class="string">""</span><span class="string">" 入口函数  "</span><span class="string">""</span> </span><br><span class="line"></span><br><span class="line">        htmls = self.__fetch_content()</span><br><span class="line">        name_number_list = self.__analysis(htmls)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将refine返回的map对象强制转换为list</span></span><br><span class="line">        name_numbers = list(self.__refine(name_number_list))</span><br><span class="line">        name_numbers = self.__sort(name_numbers)</span><br><span class="line">        self.__show(name_numbers)</span><br><span class="line"></span><br><span class="line">spider = Spider()</span><br><span class="line">spider.go()</span><br></pre></td></tr></table></figure></p>

        </div>
        <footer class="article-footer">
            



    <a data-url="http://yoursite.com/2018/07/04/十一、实战：原生爬虫/" data-id="cjjtyqf1n001qswpeqp6k2hr4" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>


                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>关注我 :</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/EdisenChai/EdisenChai.github.io" target="_blank">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="weibo" href="/" target="_blank">
                        <i class="icon fa fa-weibo"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="/atom.xml" target="_blank">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/07/05/十二、Python杂记/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">下一篇</strong>
        <p class="article-nav-title">
        
            十二、Python杂记
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2018/07/03/十、函数式编程：匿名函数、高阶函数、装饰器/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">上一篇</strong>
        <p class="article-nav-title">十、函数式编程：匿名函数、高阶函数、装饰器</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
<div class="widget-wrap widget-list">
    <h3 class="widget-title">小黑板</h3>
    <div class="widget">
        <!--这里添加你要写的内容-->
    </div>
</div>

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/20/7-proxy-use/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2018/07/20/7-proxy-use/" class="title">7-proxy-use</a></p>
                            <p class="item-date"><time datetime="2018-07-20T12:29:55.000Z" itemprop="datePublished">2018-07-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/18/6-verify-code/" class="thumbnail">
    
    
        <span style="background-image:url(/2018/07/18/6-verify-code/pic_verify.png)" alt="6-验证码的识别" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2018/07/18/6-verify-code/" class="title">6-验证码的识别</a></p>
                            <p class="item-date"><time datetime="2018-07-18T09:04:53.000Z" itemprop="datePublished">2018-07-18</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/17/5-dynamic-rendering/" class="thumbnail">
    
    
        <span style="background-image:url(/2018/07/17/5-dynamic-rendering/pikaqiu.png)" alt="5-Selenium与Splash的使用" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2018/07/17/5-dynamic-rendering/" class="title">5-Selenium与Splash的使用</a></p>
                            <p class="item-date"><time datetime="2018-07-17T11:10:07.000Z" itemprop="datePublished">2018-07-17</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/14/4-Ajax-getData/" class="thumbnail">
    
    
        <span style="background-image:url(/2018/07/14/4-Ajax-getData/pikaqiu.png)" alt="4. Ajax数据爬取" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2018/07/14/4-Ajax-getData/" class="title">4. Ajax数据爬取</a></p>
                            <p class="item-date"><time datetime="2018-07-14T12:45:28.000Z" itemprop="datePublished">2018-07-14</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/12/3-数据存储/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2018/07/12/3-数据存储/" class="title">3. 数据存储</a></p>
                            <p class="item-date"><time datetime="2018-07-12T13:52:26.000Z" itemprop="datePublished">2018-07-12</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python爬虫/">Python爬虫</a><span class="category-list-count">7</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">8</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python基础语法/">Python基础语法</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python系统课程-C1/">Python系统课程-C1</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络爬虫/">网络爬虫</a><span class="tag-list-count">7</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Python基础语法/" style="font-size: 10px;">Python基础语法</a> <a href="/tags/Python系统课程-C1/" style="font-size: 20px;">Python系统课程-C1</a> <a href="/tags/网络爬虫/" style="font-size: 15px;">网络爬虫</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">传送门</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">磨房悠悠you</a>
                    </li>
                
                    <li>
                        <a href="http://bd.kuwo.cn/yinyue/3327195?from=baidu">萝莉叔叔</a>
                    </li>
                
                    <li>
                        <a href="https://github.com/ppoffice/hexo-theme-hueman">主题</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>
                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2018 Edisen Chai</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
        </div>
    </div>
</footer>
        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'http://yoursite.com/2018/07/04/十一、实战：原生爬虫/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>
