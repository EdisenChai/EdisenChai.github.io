<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    
    <title>1.学习爬虫的基本库 | Edisenの博客</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content="网络爬虫" />
    
    <meta name="description" content="1.Python爬虫基本库的使用1.1 学习使用urllib库urllib库是Python内置的HTTP请求库之一(还有httplib2、requests、treq等)，包含以下4个模块：  request: 最基本的HTTP请求模块，用来模拟发送请求； error: 异常处理模块； parse: 一个工具模块，提供许多URL处理方法； robotparser: 主要用来识别网址的robots.t">
<meta name="keywords" content="网络爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="1.学习爬虫的基本库">
<meta property="og:url" content="http://yoursite.com/2018/07/09/1-学习爬虫的基本库/index.html">
<meta property="og:site_name" content="Edisenの博客">
<meta property="og:description" content="1.Python爬虫基本库的使用1.1 学习使用urllib库urllib库是Python内置的HTTP请求库之一(还有httplib2、requests、treq等)，包含以下4个模块：  request: 最基本的HTTP请求模块，用来模拟发送请求； error: 异常处理模块； parse: 一个工具模块，提供许多URL处理方法； robotparser: 主要用来识别网址的robots.t">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-07-11T12:34:05.566Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="1.学习爬虫的基本库">
<meta name="twitter:description" content="1.Python爬虫基本库的使用1.1 学习使用urllib库urllib库是Python内置的HTTP请求库之一(还有httplib2、requests、treq等)，包含以下4个模块：  request: 最基本的HTTP请求模块，用来模拟发送请求； error: 异常处理模块； parse: 一个工具模块，提供许多URL处理方法； robotparser: 主要用来识别网址的robots.t">
    

    
        <link rel="alternate" href="/atom.xml" title="Edisenの博客" type="application/atom+xml" />
    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.0.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    


</head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">主页</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python爬虫/">Python爬虫</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/python">Python小道</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/linux">Linux实战</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/life">随便写点儿</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/money">☞赏点儿水果☜</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">关于</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/Python爬虫/">Python爬虫</a>
    </h1>
</div>
                        <div class="main-body-content">
                            <article id="post-1-学习爬虫的基本库" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        1.学习爬虫的基本库
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2018/07/09/1-学习爬虫的基本库/" class="article-date">
            <time datetime="2018-07-09T04:33:16.000Z" itemprop="datePublished">2018-07-09</time>
        </a>
    </div>

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/网络爬虫/">网络爬虫</a>
    </div>

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h3 id="1-Python爬虫基本库的使用"><a href="#1-Python爬虫基本库的使用" class="headerlink" title="1.Python爬虫基本库的使用"></a>1.Python爬虫基本库的使用</h3><h4 id="1-1-学习使用urllib库"><a href="#1-1-学习使用urllib库" class="headerlink" title="1.1 学习使用urllib库"></a>1.1 学习使用urllib库</h4><p>urllib库是Python内置的HTTP请求库之一(还有httplib2、requests、treq等)，包含以下4个模块：</p>
<ul>
<li>request: 最基本的HTTP请求模块，用来模拟发送请求；</li>
<li>error: 异常处理模块；</li>
<li>parse: 一个工具模块，提供许多URL处理方法；</li>
<li>robotparser: 主要用来识别网址的robots.txt文件，判断网站是否可以爬取(其实用的比较少)；</li>
</ul>
<h5 id="1-1-1-发送请求-request模块"><a href="#1-1-1-发送请求-request模块" class="headerlink" title="1.1.1 发送请求(request模块)"></a>1.1.1 发送请求(request模块)</h5><p>a. urlopen()</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line"><span class="comment"># urlopen()的使用</span></span><br><span class="line">url = <span class="string">'https://www.python.org/'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回结果是一个HTTPResponse对象</span></span><br><span class="line"><span class="comment"># 了解该对象的常用 方法和属性</span></span><br><span class="line">root_htmls = urllib.request.urlopen(url)</span><br><span class="line"><span class="built_in">print</span>(root_htmls) <span class="comment">#&lt;http.client.HTTPResponse object at 0x02972030&gt;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(root_htmls)) <span class="comment">#&lt;class 'http.client.HTTPResponse'&gt; </span></span><br><span class="line"><span class="comment"># 调用对象的read()方法，读取出来具体的内容</span></span><br><span class="line">htmls = root_htmls.read().decode(<span class="string">'utf-8'</span>) <span class="comment"># 添加编码格式，输出结果看起来舒服</span></span><br><span class="line"><span class="built_in">print</span>(htmls) </span><br><span class="line"><span class="comment"># 求响应头的Server值</span></span><br><span class="line">server_name = root_htmls.getheader(<span class="string">'Server'</span>)</span><br><span class="line"><span class="built_in">print</span>(server_name) <span class="comment"># 响应头的Server值: nginx</span></span><br></pre></td></tr></table></figure>
<p>urlopen()的data参数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="comment"># urlopen()的常用参数</span></span><br><span class="line">url = <span class="string">'http://httpbin.org/post'</span></span><br><span class="line">dw = &#123;<span class="string">'word'</span>:<span class="string">'hello'</span>&#125;</span><br><span class="line"><span class="comment"># 1. data参数</span></span><br><span class="line"><span class="comment"># 先用parse.urlencode()方法将参数字典转化为字符串</span></span><br><span class="line">dw = urllib.parse.urlencode(dw)</span><br><span class="line"><span class="built_in">print</span>(dw) <span class="comment"># word=hello</span></span><br><span class="line"><span class="comment"># 使用bytes()方法将dw转化为字节流(bytes)类型</span></span><br><span class="line">data1 = bytes(dw, encoding = <span class="string">'utf8'</span>)</span><br><span class="line">res = urllib.request.urlopen(url, data= data1)</span><br><span class="line"><span class="built_in">print</span>(res.read())</span><br><span class="line"></span><br><span class="line"><span class="comment"># result:</span></span><br><span class="line">g:\Python\Demon2\new_book\basic_lib&gt;b2.py</span><br><span class="line">word=hello</span><br><span class="line">b<span class="string">'&#123;"args":&#123;&#125;,"data":"","files":&#123;&#125;,"form":&#123;"word":"hello"&#125;,"headers":&#123;"Accept-Encoding":"identity","Connection":"close","Content-Length":"10","Content-Type":"application/x-www-form-urlencoded","Host":"httpbin.org","User-Agent":"Python-urllib/3.6"&#125;,"json":null,"origin":"61.158.149.229","url":"http://httpbin.org/post"&#125;\n'</span></span><br></pre></td></tr></table></figure>
<p>urlopen()的timeout参数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.error</span><br><span class="line">import socket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. timeout参数 设置超时时间，</span></span><br><span class="line"><span class="comment"># 请求超出时间还没得到响应，就会抛出异常</span></span><br><span class="line">urlt = <span class="string">'http://httpbin.org/get'</span></span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    troot_htmls = urllib.request.urlopen(urlt, timeout=0.01)</span><br><span class="line">    thtmls = troot_htmls.read()</span><br><span class="line">    <span class="built_in">print</span>(troot_htmls)</span><br><span class="line"><span class="comment"># 判断URLError 是不是socket.timeout类型(超时异常)    </span></span><br><span class="line">except urllib.error.URLError  as e:</span><br><span class="line">    <span class="keyword">if</span> isinstance(e.reason, socket.timeout):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">'TIME OUT'</span>)</span><br></pre></td></tr></table></figure>
<p>b. Request</p>
<p>urlopen()只能实现最基本的请求的发起，如果要构建完整的请求，就需要利用更强大的Request类在请求中加入Headers等信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request, parser</span><br><span class="line"></span><br><span class="line">URL = <span class="string">'http://httpbin.org/post'</span></span><br><span class="line">data_ori = &#123;<span class="string">'name'</span>:<span class="string">'Tom'</span>&#125;</span><br><span class="line">data_pu = urllib.parse.urlencode(data_ori)</span><br><span class="line">data = bytes(data_pu, encoding= <span class="string">'utf8'</span>)</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0'</span>,</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'httpbin.org'</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 URL构建为一个Request对象，进而更加丰富和灵活的配置参数</span></span><br><span class="line"><span class="comment"># 加入url、data、headers、method等常用参数</span></span><br><span class="line">req = urllib.request.Request(URL, data= data, headers= headers,method= <span class="string">'POST'</span>)</span><br><span class="line"><span class="comment">#也可以通过以下方法，直接添加 headers</span></span><br><span class="line"><span class="comment"># req2 = request.Request(URL, data=data,method='POST')</span></span><br><span class="line"><span class="comment"># req2.add_header(headers)</span></span><br><span class="line"><span class="built_in">print</span>(req)</span><br><span class="line">root_htmls = urllib.request.urlopen(req)</span><br><span class="line">htmls = root_htmls.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="built_in">print</span>(htmls)</span><br><span class="line"></span><br><span class="line"><span class="comment">#result：</span></span><br><span class="line">g:\Python\Demon2\new_book\basic_lib&gt;b4.py</span><br><span class="line">&lt;urllib.request.Request object at 0x01F02AD0&gt;</span><br><span class="line">&#123;<span class="string">"args"</span>:&#123;&#125;,<span class="string">"data"</span>:<span class="string">""</span>,<span class="string">"files"</span>:&#123;&#125;,<span class="string">"form"</span>:&#123;<span class="string">"name"</span>:<span class="string">"Tom"</span>&#125;,<span class="string">"headers"</span>:&#123;<span class="string">"Accept-Encoding"</span>:<span class="string">"identity"</span>,<span class="string">"Connection"</span>:<span class="string">"close"</span>,<span class="string">"Content-Length"</span>:<span class="string">"8"</span>,<span class="string">"Content-Type"</span>:<span class="string">"application/x-www-form-urlencoded"</span>,<span class="string">"Host"</span>:<span class="string">"httpbin.org"</span>,<span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0"</span>&#125;,<span class="string">"json"</span>:null,<span class="string">"origin"</span>:<span class="string">"61.158.149.5"</span>,<span class="string">"url"</span>:<span class="string">"http://httpbin.org/post"</span>&#125;</span><br></pre></td></tr></table></figure>
<p>c. 高级用法：Cookies处理、代理设置、登录验证等</p>
<p>urllib.request模块里的BaseHandler类(各种处理器)可以完成这些功能，现列出其常用子类：</p>
<ul>
<li>HTTPDefaultErrorHandler:处理HTTP响应错误，抛出HTTPError;</li>
<li>HTTPRedirectHandler: 用于处理重定向;</li>
<li>HTTPCookieProcessor: 用于处理Cookies;</li>
<li>ProxyHandler: 用于设置代理，默认代理为空;</li>
<li>HTTPPasswordMgr: 用于管理密码，维护了用户名和密码表;</li>
<li>HTTPBasicAuthHandler: 用于管理认证，若一个连接打开时需要认证，则可用其解决认证问题;</li>
</ul>
<h5 id="打开需要身份验证的网站"><a href="#打开需要身份验证的网站" class="headerlink" title="打开需要身份验证的网站"></a>打开需要身份验证的网站</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request import HTTPPasswordMgrWithDefaultRealm,HTTPBasicAuthHandler,build_opener,OpenerDirector</span><br><span class="line">from urllib.error import URLError</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开需要身份验证的网站</span></span><br><span class="line"></span><br><span class="line">username = <span class="string">'zhangsan'</span></span><br><span class="line"><span class="built_in">pwd</span> = <span class="string">'3'</span></span><br><span class="line">url = <span class="string">'http://localhost:5000/'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#构建一个HTTPPasswordMgrWithDefaultRealm对象</span></span><br><span class="line">p = HTTPPasswordMgrWithDefaultRealm()</span><br><span class="line"><span class="comment"># 将设置好的url、账号、密码加进去</span></span><br><span class="line">p.add_password(None, url, username, <span class="built_in">pwd</span>)</span><br><span class="line"><span class="comment">#实例化HTTPBasicAuthHandler类，建立一个处理验证的Handler</span></span><br><span class="line">auth_handler = HTTPBasicAuthHandler(p)</span><br><span class="line"><span class="comment"># 将Handler传过来，利用build_opener，构建一个Opener</span></span><br><span class="line">opener = build_opener(auth_handler)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    <span class="comment"># 获得验证后的页面源码内容</span></span><br><span class="line">    result = opener.open(url)</span><br><span class="line">    html = result.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="built_in">print</span>(html)</span><br><span class="line">except URLError as e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></table></figure>
<h5 id="代理设置"><a href="#代理设置" class="headerlink" title="代理设置"></a>代理设置</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from urllib.error import URLError</span><br><span class="line">from urllib.request import ProxyHandler,build_opener</span><br><span class="line"></span><br><span class="line"><span class="comment"># 代理设置</span></span><br><span class="line">url = <span class="string">'https://www.baidu.com/'</span></span><br><span class="line"><span class="comment"># 本地搭建的代理，运行在9743端口</span></span><br><span class="line">ph = &#123;<span class="string">'http'</span>:<span class="string">'http://127.0.0.1:9743'</span>,</span><br><span class="line">      <span class="string">'https'</span>:<span class="string">'https://127.0.0.1:9743'</span>&#125;</span><br><span class="line"></span><br><span class="line">proxy_handler = ProxyHandler(ph)</span><br><span class="line">opener = build_opener(proxy_handler)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    res = opener.open(url)</span><br><span class="line">    htmls = res.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="built_in">print</span>(htmls)</span><br><span class="line">except URLError as e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br></pre></td></tr></table></figure>
<h5 id="Coockies处理"><a href="#Coockies处理" class="headerlink" title="Coockies处理"></a>Coockies处理</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">import http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment">#Coockies处理</span></span><br><span class="line">url = <span class="string">'https://www.baidu.com/'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#声明一个CookieJar对象</span></span><br><span class="line">cookie = http.cookiejar.CookieJar()</span><br><span class="line"><span class="comment">#利用HTTPCookieProcessor构建一个handler对象</span></span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line"><span class="comment"># 利用build_opener构建出opener, 再执行open()函数\方法</span></span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">res = opener.open(url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookie:</span><br><span class="line">    <span class="built_in">print</span>(item.name + <span class="string">' = '</span> +item.value)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'===将Cookies以文本形式输出(Mozilla型浏览器格式)==='</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将Cookies以文本形式输出(Mozilla型浏览器的Cookies格式)</span></span><br><span class="line">url2 = <span class="string">'https://www.baidu.com/'</span></span><br><span class="line">filename = <span class="string">'cookies.txt'</span></span><br><span class="line"><span class="comment">#MozillaCookieJar是CookieJar的子类，</span></span><br><span class="line"><span class="comment"># 用来处理Cookies和文件相关的事情，比如读取和保存Cookies</span></span><br><span class="line"><span class="comment"># 将cookies保存成Mozilla型浏览器的Cookies格式</span></span><br><span class="line">cookie2 = http.cookiejar.MozillaCookieJar(filename)</span><br><span class="line">handler2 = urllib.request.HTTPCookieProcessor(cookie2)</span><br><span class="line">opener2 = urllib.request.build_opener(handler2)</span><br><span class="line">res2 = opener2.open(url2)</span><br><span class="line">cookie2.save(ignore_discard=True, ignore_expires=True)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'===将Cookies以文本形式输出(LWP格式)==='</span>)</span><br><span class="line"><span class="comment">#将Cookies以文本形式输出(LWP格式)</span></span><br><span class="line">url3 = <span class="string">'https://www.baidu.com/'</span></span><br><span class="line">filename3 = <span class="string">'3cookies.txt'</span></span><br><span class="line"></span><br><span class="line">cookie3 = http.cookiejar.LWPCookieJar(filename3)</span><br><span class="line">handler3 = urllib.request.HTTPCookieProcessor(cookie3)</span><br><span class="line">opener3 = urllib.request.build_opener(handler3)</span><br><span class="line">res3 = opener3.open(url3)</span><br><span class="line">cookie3.save(ignore_discard=True, ignore_expires=True)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'===读取本地Cookies文件'</span>)</span><br><span class="line"></span><br><span class="line">cookie_get = http.cookiejar.LWPCookieJar()</span><br><span class="line">cookie_get.load(filename3,ignore_discard=True, ignore_expires=True)</span><br><span class="line">handler4 = urllib.request.HTTPCookieProcessor(cookie_get)</span><br><span class="line">opener4 = urllib.request.build_opener(handler4)</span><br><span class="line">res4 = opener4.open(url3)</span><br><span class="line">res4_r = res4.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="built_in">print</span>(res4_r)</span><br></pre></td></tr></table></figure>
<h5 id="1-1-2-处理异常-error模块"><a href="#1-1-2-处理异常-error模块" class="headerlink" title="1.1.2 处理异常(error模块)"></a>1.1.2 处理异常(error模块)</h5><p>防止网络不稳定不好的状况下，程序出现异常而停止运行。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">from urllib import request,error</span><br><span class="line">import socket</span><br><span class="line"><span class="comment">#异常处理</span></span><br><span class="line">url = <span class="string">'https://cuiqingcai.com/index.htm'</span></span><br><span class="line">try:</span><br><span class="line">    res = request.urlopen(url)</span><br><span class="line">    <span class="built_in">print</span>(res.read().decode(<span class="string">'utf-8'</span>))</span><br><span class="line"><span class="comment"># HTTPError 是 URLError 的子类</span></span><br><span class="line">except error.HTTPError as e:</span><br><span class="line">    <span class="built_in">print</span>(e.reason, e.code, e.headers, sep=<span class="string">'\n'</span>)</span><br><span class="line">except error.URLError as e:</span><br><span class="line">    <span class="keyword">if</span> isinstance(e.reason,socket.timeout):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">'timeout'</span>)</span><br><span class="line">    <span class="built_in">print</span>(e.reason)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'request successfully'</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># result:</span></span><br><span class="line">g:\Python\Demon2\new_book\basic_lib&gt;b8.py</span><br><span class="line">Not Found</span><br><span class="line">404</span><br><span class="line">Server: nginx/1.10.3 (Ubuntu)</span><br><span class="line">Date: Tue, 10 Jul 2018 05:58:21 GMT</span><br><span class="line">Content-Type: text/html; charset=UTF-8</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">Connection: close</span><br><span class="line">Vary: Cookie</span><br><span class="line">Expires: Wed, 11 Jan 1984 05:00:00 GMT</span><br><span class="line">Cache-Control: no-cache, must-revalidate, max-age=0</span><br><span class="line">Link: &lt;https://cuiqingcai.com/wp-json/&gt;; rel=<span class="string">"https://api.w.org/"</span></span><br></pre></td></tr></table></figure></p>
<h5 id="1-1-3-解析连接-parse模块"><a href="#1-1-3-解析连接-parse模块" class="headerlink" title="1.1.3 解析连接(parse模块)"></a>1.1.3 解析连接(parse模块)</h5><p>parse定义了处理URL的标准接口。</p>
<p>a. urlparse()</p>
<p>实现url的识别和分段,拆为6个部分:scheme、netloc、path、params、query、fragment<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from urllib.parse import urlparse</span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.baidu.com/index.html;user?id=5#comment'</span></span><br><span class="line">result = urlparse(url,scheme=<span class="string">'http'</span>,allow_fragments=True)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(result)) <span class="comment">#&lt;class 'urllib.parse.ParseResult'&gt;</span></span><br><span class="line"><span class="built_in">print</span>(result) </span><br><span class="line"><span class="comment">#ParseResult(scheme='https', netloc='www.baidu.com', </span></span><br><span class="line"><span class="comment">#path='/index.html', params='user', query='id=5', fragment='comment'</span></span><br><span class="line"><span class="built_in">print</span>(result.scheme, result.netloc, result.path, result.params, </span><br><span class="line">      result.query, result.fragment,sep = <span class="string">'\n'</span>)</span><br><span class="line"><span class="built_in">print</span>(result[0], result[1])<span class="comment"># https www.baidu.com</span></span><br></pre></td></tr></table></figure></p>
<p>b. urlunparse()</p>
<p>url组合，合并连接，接受的参数是一个可迭代对象(可以被遍历)，且长度必须是6.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from urllib.parse import urlunparse</span><br><span class="line"></span><br><span class="line">url_data = [<span class="string">'https'</span>,<span class="string">'www.baidu.com'</span>,<span class="string">'/index.html'</span>,</span><br><span class="line">             <span class="string">'user'</span>,<span class="string">'id=5'</span>,<span class="string">'comment'</span>]</span><br><span class="line">url = urlunparse(url_data)</span><br><span class="line"><span class="built_in">print</span>(url)</span><br><span class="line"><span class="comment">#https://www.baidu.com/index.html;user?id=5#comment</span></span><br></pre></td></tr></table></figure></p>
<p>c. urlsplit()</p>
<p>同urlparse()很像，只是拆解url时，少了params(合并到path中)这一部分<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from urllib.parse  import urlsplit</span><br><span class="line"></span><br><span class="line">url2 = <span class="string">'https://www.baidu.com/index.html;user?id=5#comment'</span></span><br><span class="line">data = urlsplit(url2)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line"><span class="comment">#SplitResult(scheme='https', netloc='www.baidu.com', </span></span><br><span class="line"><span class="comment"># path='/index.html;user', query='id=5', fragment='comment')</span></span><br><span class="line"><span class="built_in">print</span>(data.netloc,data[1],end=<span class="string">'\n'</span>)</span><br><span class="line"><span class="comment"># www.baidu.com www.baidu.com</span></span><br></pre></td></tr></table></figure></p>
<p>d. urlunsplit()</p>
<p>同urlunparse()很像，传入参数也必须是一个可迭代对象，区别是长度必须为5<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from urllib.parse import urlunsplit</span><br><span class="line"></span><br><span class="line">url_data2 = [<span class="string">'https'</span>,<span class="string">'www.baidu.com'</span>,<span class="string">'index.html'</span>,</span><br><span class="line">             <span class="string">'id=5'</span>,<span class="string">'comment'</span>]</span><br><span class="line">url3 = urlunsplit(url_data2)</span><br><span class="line"><span class="built_in">print</span>(url3)</span><br><span class="line"><span class="comment"># https://www.baidu.com/index.html?id=5#comment</span></span><br></pre></td></tr></table></figure></p>
<p>e. urljoin()</p>
<p>也是将连接合并，接受两个参数，将第一个base_url(基础连接)作为第一个参数，新的连接作为第二个参数，该方法会分析base_url的scheme、netloc和path这三个内容，并对新连接缺失的内容进行补充，最后返回结果。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from urllib.parse import urljoin</span><br><span class="line"></span><br><span class="line">base_url1 = <span class="string">'https://www.baidu.com'</span></span><br><span class="line">base_url2 = <span class="string">'https://www.baidu.com/anb.html'</span></span><br><span class="line">base_url3 = <span class="string">'https://www.baidu.com?qwae=87'</span></span><br><span class="line">base_url4 = <span class="string">'www.baidu.com'</span></span><br><span class="line">base_url5 = <span class="string">'www.baidu.com#ojbk'</span></span><br><span class="line">new_url1 = <span class="string">'https://cuiqingcai.com/FS.htm'</span></span><br><span class="line">new_url2 = <span class="string">'?category=2#sdf'</span></span><br><span class="line"></span><br><span class="line">u1 = urljoin(base_url1, <span class="string">'FS.html'</span>)</span><br><span class="line">u2 = urljoin(base_url2, new_url1)</span><br><span class="line">u3 = urljoin(base_url3, new_url1)</span><br><span class="line">u4 = urljoin(base_url4, new_url2)</span><br><span class="line">u5 = urljoin(base_url5, new_url2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(u1)<span class="comment">#https://www.baidu.com/FS.html</span></span><br><span class="line"><span class="built_in">print</span>(u2) <span class="comment">#https://cuiqingcai.com/FS.htm</span></span><br><span class="line"><span class="built_in">print</span>(u3)<span class="comment">#https://cuiqingcai.com/FS.htm</span></span><br><span class="line"><span class="built_in">print</span>(u4) <span class="comment">#www.baidu.com?category=2#sdf</span></span><br><span class="line"><span class="built_in">print</span>(u5)<span class="comment">#www.baidu.com?category=2#sdf</span></span><br></pre></td></tr></table></figure>
<p>可见，base_url 提供了3项内容scheme、netloc及path。当这3项在新连接里不存在时，就予以补充，新连接里有的话，就用新连接自己的；base_url中的params、query和fragment是不起作用的。</p>
<h4 id="f-urlencode"><a href="#f-urlencode" class="headerlink" title="f. urlencode()"></a>f. urlencode()</h4><p>此方法在构造GET请求参数时非常有用,将字典类型的参数转化为GET请求的参数。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from urllib.parse import urlencode</span><br><span class="line"></span><br><span class="line">query = &#123;<span class="string">'name'</span>:<span class="string">'Jou'</span>,<span class="string">'age'</span>:2&#125;</span><br><span class="line">query = urlencode(query)</span><br><span class="line"><span class="built_in">print</span>(query) <span class="comment"># name=Jou&amp;age=2</span></span><br><span class="line">base_url = <span class="string">'https://www.baidu.com?'</span></span><br><span class="line">url = base_url + query</span><br><span class="line"><span class="built_in">print</span>(url) <span class="comment">#https://www.baidu.com?name=Jou&amp;age=2</span></span><br></pre></td></tr></table></figure></p>
<p>g. parse_qs()与parse_qsl()</p>
<p>二者与urlencode()相反的功能：<br>1.parse_qs()将GET请求参数转化为字典类型;<br>2.parse_qsl()将GET请求参数转化为元组组成的列表;</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from urllib.parse import parse_qs, parse_qsl</span><br><span class="line"></span><br><span class="line">query2 = <span class="string">'name=Jou&amp;age=2'</span></span><br><span class="line">data = parse_qs(query2)</span><br><span class="line"><span class="built_in">print</span>(data)<span class="comment"># &#123;'name': ['Jou'], 'age': ['2']&#125;</span></span><br><span class="line"></span><br><span class="line">data2 = parse_qsl(query2)</span><br><span class="line"><span class="built_in">print</span>(data2)<span class="comment"># [('name', 'Jou'), ('age', '2')]</span></span><br></pre></td></tr></table></figure>
<p>h.中文字符转URL编码与反转–qutoe()及unqutoe()</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from urllib.parse import quote,unquote</span><br><span class="line"></span><br><span class="line">keyword = <span class="string">'你好'</span></span><br><span class="line">url = <span class="string">'https://www.baidu.com?'</span></span><br><span class="line">qk = quote(keyword) </span><br><span class="line"><span class="built_in">print</span>(qk) <span class="comment"># %E4%BD%A0%E5%A5%BD</span></span><br><span class="line">url = url + qk </span><br><span class="line"><span class="built_in">print</span>(url) <span class="comment"># https://www.baidu.com?%E4%BD%A0%E5%A5%BD</span></span><br><span class="line"></span><br><span class="line">kw = unquote(qk)</span><br><span class="line">url_kw = unquote(url)</span><br><span class="line"><span class="built_in">print</span>(kw) <span class="comment"># 你好</span></span><br><span class="line"><span class="built_in">print</span>(url_kw) <span class="comment"># https://www.baidu.com?你好</span></span><br></pre></td></tr></table></figure>
<h5 id="1-1-4-Robots协议分析-robotparser模块"><a href="#1-1-4-Robots协议分析-robotparser模块" class="headerlink" title="1.1.4 Robots协议分析(robotparser模块)"></a>1.1.4 Robots协议分析(robotparser模块)</h5><p>也被称为爬虫协议、机器协议，全名叫网络爬虫排除标准，用来告诉爬虫和搜索引擎哪些页面可以爬取，哪些不可以爬取；<br>robotparser模块提供了一个类RobotFileParser,它可以根据某网站的robots.txt文件来判断一个爬虫是否有权限来爬取这个网页。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from urllib.robotparser import RobotFileParser</span><br><span class="line"><span class="comment"># 创建一个RobotFileParser对象</span></span><br><span class="line">rb = RobotFileParser()</span><br><span class="line">url = <span class="string">'http://www.jianshu.com/robots.txt'</span></span><br><span class="line">url_fetch1 = <span class="string">'http://www.jianshu.com/p/b67554025d7d'</span></span><br><span class="line">url_fetch=<span class="string">'http://www.jianshu.com/search?q=python&amp;page=1&amp;type=collections'</span></span><br><span class="line">url2 = <span class="string">'https://www.jianshu.com/'</span></span><br><span class="line"><span class="comment"># 接收robots.txt连接参数，判断是否有权限爬取</span></span><br><span class="line">rb.set_url(url)</span><br><span class="line"><span class="comment">#读取robots.txt文件并分析</span></span><br><span class="line">rb.read()</span><br><span class="line">rbool = rb.can_fetch(<span class="string">'*'</span>, url2)</span><br><span class="line">r1bool = rb.can_fetch(<span class="string">'*'</span>, url_fetch1)</span><br><span class="line">r2bool = rb.can_fetch(<span class="string">'*'</span>, url_fetch)</span><br><span class="line"><span class="built_in">print</span>(rbool) <span class="comment">#False</span></span><br><span class="line"><span class="built_in">print</span>(r1bool) <span class="comment">#False</span></span><br><span class="line"><span class="built_in">print</span>(r2bool) <span class="comment">#False</span></span><br></pre></td></tr></table></figure></p>
<h4 id="1-2-requests库的使用"><a href="#1-2-requests库的使用" class="headerlink" title="1.2 requests库的使用"></a>1.2 requests库的使用</h4><h5 id="1-2-1-基本用法"><a href="#1-2-1-基本用法" class="headerlink" title="1.2.1 基本用法"></a>1.2.1 基本用法</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.baidu.com/'</span></span><br><span class="line">url_post = <span class="string">'http://httpbin.org/post'</span></span><br><span class="line">url_put = <span class="string">'http://httpbin.org/put'</span></span><br><span class="line">url_delete = <span class="string">'http://httpbin.org/delete'</span></span><br><span class="line">url_get = <span class="string">'http://httpbin.org/get'</span></span><br><span class="line">r1 = requests.post(url_post)</span><br><span class="line">r2 = requests.put(url_put)</span><br><span class="line">r3 = requests.delete(url_delete)</span><br><span class="line">r4 = requests.head(url_get)</span><br><span class="line">r5 = requests.options(url_get)</span><br><span class="line"></span><br><span class="line">r = requests.get(url)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r))</span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.text))</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br><span class="line"><span class="built_in">print</span>(r.cookies)</span><br></pre></td></tr></table></figure>
<p>GET()请求</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">url = <span class="string">'http://httpbin.org/get'</span></span><br><span class="line">data = &#123;<span class="string">'name'</span>:<span class="string">'Jim'</span>,<span class="string">'age'</span>:18&#125;</span><br><span class="line">r = requests.get(url, data)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># r2 = requests.get(url)</span></span><br><span class="line"><span class="comment"># print(type(r2))</span></span><br><span class="line"><span class="comment"># print(type(r2.text))</span></span><br><span class="line"><span class="built_in">print</span>(r.json())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r.json()))</span><br></pre></td></tr></table></figure>
<p>知乎问题抓取：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line"><span class="comment">#爬取知乎问题</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.zhihu.com/explore'</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) \</span></span><br><span class="line"><span class="string">    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'</span>&#125;</span><br><span class="line">r = requests.get(url,headers= headers)</span><br><span class="line"><span class="comment"># print(r.text)</span></span><br><span class="line">pattern = re.compile(<span class="string">'explore-feed.*?question_link.*?&gt;(.*?)&lt;/a&gt;'</span>,re.S)</span><br><span class="line">titles = re.findall(pattern,r.text)</span><br><span class="line"><span class="built_in">print</span>(titles)</span><br></pre></td></tr></table></figure>
<p>github图标抓取</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 抓取github图标</span></span><br><span class="line">url = <span class="string">'https://github.com/favicon.ico'</span></span><br><span class="line"></span><br><span class="line">r = requests.get(url)</span><br><span class="line"><span class="comment"># print(r.text)</span></span><br><span class="line"><span class="comment"># print(r.content)</span></span><br><span class="line">with open(<span class="string">'github.pic'</span>,<span class="string">'wb'</span>) as f:</span><br><span class="line">    f.write(r.content)</span><br></pre></td></tr></table></figure>
<h5 id="1-2-2-高级用法"><a href="#1-2-2-高级用法" class="headerlink" title="1.2.2 高级用法"></a>1.2.2 高级用法</h5><p>a. 文件上传</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件上传</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://httpbin.org/post'</span></span><br><span class="line"></span><br><span class="line">files = &#123;<span class="string">'file'</span>:open(<span class="string">'github.pic'</span>,<span class="string">'rb'</span>)&#125;</span><br><span class="line">r = requests.post(url, files=files)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>
<p>b. Cookies</p>
<p>使用requests来使用设置Cookies都很简洁：<br>1.获取Cookie<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.baidu.com/'</span></span><br><span class="line">r = requests.get(url)</span><br><span class="line">cookies_baidu = r.cookies</span><br><span class="line"><span class="built_in">print</span>(cookies_baidu) </span><br><span class="line"><span class="comment">#&lt;RequestsCookieJar[&lt;Cookie BDORZ=27315 for .baidu.com/&gt;]&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#利用items()方法将其转化为元组组成的列表,实现Cookie的遍历解析</span></span><br><span class="line"><span class="built_in">print</span>(cookies_baidu.items()) <span class="comment"># [('BDORZ', '27315')]</span></span><br><span class="line"><span class="keyword">for</span> key,value <span class="keyword">in</span> cookies_baidu.items():</span><br><span class="line">    <span class="built_in">print</span>(key+<span class="string">':'</span>+value)</span><br><span class="line"><span class="comment">#BDORZ:27315</span></span><br></pre></td></tr></table></figure></p>
<ol start="2">
<li>利用Cookies维持登录状态<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用Cookies维持知乎登录状态</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.zhihu.com/'</span></span><br><span class="line">headers = &#123; </span><br><span class="line">    <span class="string">'Cookies'</span>: <span class="string">'_zap=c74ffe60-fc10-4d88-8507-8b2f094ffe47; \</span></span><br><span class="line"><span class="string">    z_c0="2|1:0|10:1524489650|4:z_c0|92:Mi4xQU5UbkFnQUFBQUFB\</span></span><br><span class="line"><span class="string">    QUtDRUdyNThEU1lBQUFCZ0FsVk5zaXZMV3dBR1VjamtZZ3NWWVZBbjZEUV\</span></span><br><span class="line"><span class="string">    JFbElrTGpoOGZn|9ccd196c7209f86d929e45a1390e95ba02dc65699bce56\</span></span><br><span class="line"><span class="string">    f85c4725dec94e1365"; d_c0="ABBh7ahaiA2PTpF7sbd2mFngNGhU8hYDlnk=|1525268870";\</span></span><br><span class="line"><span class="string">     _xsrf=783a0476-0ab1-43a0-8d65-c5762532455d; q_c1=14b00bbf304245c79d6eb10cdb7\</span></span><br><span class="line"><span class="string">     195f6|1530178859000|1524489635000; __utmc=518543923; __utmv=51854390.100--|2=re\</span></span><br><span class="line"><span class="string">     gistration_date=20160419=1^3=entry_date=20160419=1; tgw_l7_route=69f52e0ac392bb4\</span></span><br><span class="line"><span class="string">     3ffb22fc18a173ee6; __utma=51854390.1263074800.1531224527.1531276507.1531281798.3; \</span></span><br><span class="line"><span class="string">     __utmb=51854390.0.10.1531281798; __utmz=51854390.1531281798.3.3.utmcsr=zhihu.com|u\</span></span><br><span class="line"><span class="string">     tmccn=(referral)|utmcmd=referral|utmcct=/'</span>,</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'www.zhihu.com'</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \</span></span><br><span class="line"><span class="string">    Chrome/67.0.3396.99 Safari/537.36'</span> </span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(url, headers= headers) </span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>c. 会话维持(Session)</p>
<p>Session模拟在一个浏览器中打开同一个站点的不同页面，模拟登录成功后接下来的一些操作。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line"><span class="comment">#Session 会话维持</span></span><br><span class="line"></span><br><span class="line">url_set = <span class="string">'http://httpbin.org/cookies/set/number/1234'</span></span><br><span class="line">url_get = <span class="string">'http://httpbin.org/cookies'</span></span><br><span class="line">s = requests.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求此网站时，设置一个cookie,名字是number,值是1234</span></span><br><span class="line">rs = s.get(url_set)</span><br><span class="line"><span class="built_in">print</span>(rs.text)</span><br><span class="line"></span><br><span class="line"><span class="comment">#请求此网址获取当前的Cookies</span></span><br><span class="line">r = s.get(url_get)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure></p>
<p>d. SSL证书验证</p>
<p>…</p>
<p>爬取猫眼电影TOP100</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""</span><span class="string">" </span></span><br><span class="line"><span class="string">爬取猫眼电影TOP100 </span></span><br><span class="line"><span class="string">电影名称、时间、评分、图片 等信息</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import json</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">class MaoYanSpider():</span><br><span class="line"></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span></span><br><span class="line"></span><br><span class="line">    title_pattern = <span class="string">'&lt;dd&gt;.*?name.*?a.*?&gt;(.*?)&lt;/a&gt;'</span></span><br><span class="line">    rank_pattern = <span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;'</span></span><br><span class="line">    pic_pattern = <span class="string">'&lt;dd&gt;.*?data-src="(.*?)@160w'</span></span><br><span class="line">    actor_pattern = <span class="string">'&lt;dd&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;'</span></span><br><span class="line">    time_pattern = <span class="string">'&lt;dd&gt;.*?releasetime"&gt;(.*?)&lt;/p&gt;'</span></span><br><span class="line">    score_pattern = <span class="string">'&lt;dd&gt;.*?score.*?i.*?&gt;(.*?)&lt;/i&gt;.*?i.*?&gt;(.*?)&lt;/i&gt;'</span></span><br><span class="line"></span><br><span class="line">    def get_one_page(self):</span><br><span class="line"></span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit\</span></span><br><span class="line"><span class="string">            /537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'</span></span><br><span class="line">        &#125;</span><br><span class="line">        response = requests.get(MaoYanSpider.url, headers= headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == 200:</span><br><span class="line">            <span class="built_in">return</span> response.text</span><br><span class="line">        <span class="built_in">return</span> None</span><br><span class="line"></span><br><span class="line">    def refine(self,root_htmls):</span><br><span class="line">        titles = re.findall(MaoYanSpider.title_pattern, root_htmls, re.S)</span><br><span class="line">        rank = re.findall(MaoYanSpider.rank_pattern, root_htmls, re.S)</span><br><span class="line">        pics = re.findall(MaoYanSpider.pic_pattern, root_htmls, re.S)</span><br><span class="line">        actors = re.findall(MaoYanSpider.actor_pattern, root_htmls, re.S)</span><br><span class="line">        actors_new = []</span><br><span class="line">        <span class="keyword">for</span> actor <span class="keyword">in</span> actors:</span><br><span class="line">            actors_new.append(actor.strip())</span><br><span class="line">        time = re.findall(MaoYanSpider.time_pattern, root_htmls, re.S)</span><br><span class="line">        score = re.findall(MaoYanSpider.score_pattern, root_htmls, re.S)</span><br><span class="line">        score_new = []</span><br><span class="line">        <span class="keyword">for</span> sc <span class="keyword">in</span> score:</span><br><span class="line">            score_new.append(sc[0]+sc[1])</span><br><span class="line">        </span><br><span class="line">        info_movie = []</span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(0,len(titles)):</span><br><span class="line">            info_movie.append(&#123;</span><br><span class="line">                <span class="string">'Title'</span>:titles[index],<span class="string">'Rank'</span>:rank[index],<span class="string">'Actor'</span>:actors_new[index],</span><br><span class="line">                <span class="string">'Time'</span>:time[index],<span class="string">'Score'</span>:score_new[index],<span class="string">'Img'</span>:pics[index]</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">return</span> info_movie</span><br><span class="line"></span><br><span class="line">    def write_to_file(self,info_movie):</span><br><span class="line">        </span><br><span class="line">        with open(<span class="string">'movie_rank_info.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>) as f:</span><br><span class="line">            contents = json.dumps(info_movie,ensure_ascii=False)</span><br><span class="line">            f.write(contents+<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">    def main(self):</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">            number = [0,10,20,30,40,50,60,70,80,90]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> number:</span><br><span class="line">                offset = i</span><br><span class="line">                time.sleep(1)</span><br><span class="line">                MaoYanSpider.url = MaoYanSpider.url + str(offset)</span><br><span class="line">                <span class="built_in">print</span>(MaoYanSpider.url)</span><br><span class="line">                root_htmls = self.get_one_page()</span><br><span class="line">                info_movie = self.refine(root_htmls)</span><br><span class="line">                self.write_to_file(info_movie)</span><br><span class="line">                MaoYanSpider.url = <span class="string">'http://maoyan.com/board/4?offset='</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">maoyan = MaoYanSpider()</span><br><span class="line">maoyan.main()</span><br></pre></td></tr></table></figure>

        </div>
        <footer class="article-footer">
            



    <a data-url="http://yoursite.com/2018/07/09/1-学习爬虫的基本库/" data-id="cjjim6fp20001e4pe90sq9qd1" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>


                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>关注我 :</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/EdisenChai/EdisenChai.github.io" target="_blank">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="weibo" href="/" target="_blank">
                        <i class="icon fa fa-weibo"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="/atom.xml" target="_blank">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/07/10/2-解析库的使用/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">下一篇</strong>
        <p class="article-nav-title">
        
            2. 解析库的使用
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2018/07/05/十二、Python杂记/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">上一篇</strong>
        <p class="article-nav-title">十二、Python杂记</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
<div class="widget-wrap widget-list">
    <h3 class="widget-title">小黑板</h3>
    <div class="widget">
        <!--这里添加你要写的内容-->
    </div>
</div>

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/12/3-data-stored/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2018/07/12/3-data-stored/" class="title">3-data-stored</a></p>
                            <p class="item-date"><time datetime="2018-07-12T13:52:26.000Z" itemprop="datePublished">2018-07-12</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/10/2-解析库的使用/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2018/07/10/2-解析库的使用/" class="title">2. 解析库的使用</a></p>
                            <p class="item-date"><time datetime="2018-07-10T01:13:42.000Z" itemprop="datePublished">2018-07-10</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/09/1-学习爬虫的基本库/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2018/07/09/1-学习爬虫的基本库/" class="title">1.学习爬虫的基本库</a></p>
                            <p class="item-date"><time datetime="2018-07-09T04:33:16.000Z" itemprop="datePublished">2018-07-09</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/05/十二、Python杂记/" class="thumbnail">
    
    
        <span style="background-image:url(/2018/07/05/十二、Python杂记/pikaqiu.png)" alt="十二、Python杂记" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a></p>
                            <p class="item-title"><a href="/2018/07/05/十二、Python杂记/" class="title">十二、Python杂记</a></p>
                            <p class="item-date"><time datetime="2018-07-05T08:11:19.000Z" itemprop="datePublished">2018-07-05</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/04/十一、实战：原生爬虫/" class="thumbnail">
    
    
        <span style="background-image:url(/2018/07/04/十一、实战：原生爬虫/spider.png)" alt="十一、实战：原生爬虫" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a></p>
                            <p class="item-title"><a href="/2018/07/04/十一、实战：原生爬虫/" class="title">十一、实战：原生爬虫</a></p>
                            <p class="item-date"><time datetime="2018-07-04T05:22:56.000Z" itemprop="datePublished">2018-07-04</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python爬虫/">Python爬虫</a><span class="category-list-count">3</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">8</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python基础语法/">Python基础语法</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python系统课程-C1/">Python系统课程-C1</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络爬虫/">网络爬虫</a><span class="tag-list-count">3</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Python基础语法/" style="font-size: 10px;">Python基础语法</a> <a href="/tags/Python系统课程-C1/" style="font-size: 20px;">Python系统课程-C1</a> <a href="/tags/网络爬虫/" style="font-size: 10px;">网络爬虫</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">传送门</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">磨房悠悠you</a>
                    </li>
                
                    <li>
                        <a href="http://bd.kuwo.cn/yinyue/3327195?from=baidu">萝莉叔叔</a>
                    </li>
                
                    <li>
                        <a href="https://github.com/ppoffice/hexo-theme-hueman">主题</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>
                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2018 Edisen Chai</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
        </div>
    </div>
</footer>
        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'http://yoursite.com/2018/07/09/1-学习爬虫的基本库/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>
